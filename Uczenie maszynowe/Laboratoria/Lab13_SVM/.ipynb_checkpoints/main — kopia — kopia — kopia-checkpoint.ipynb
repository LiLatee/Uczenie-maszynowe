{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as plt3d\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./131767-svm.txt\", sep='\\t')\n",
    "data[:3]\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  0.7402\n",
      "1:  0.25980000000000003\n"
     ]
    }
   ],
   "source": [
    "classes_count = collections.Counter(y)\n",
    "class_0_prc = classes_count[0]/(classes_count[1]+classes_count[0])\n",
    "class_1_prc = 1 - class_0_prc\n",
    "print(\"0: \", class_0_prc)\n",
    "print(\"1: \", class_1_prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({dtype('float64'): 119})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(X.dtypes)\n",
    "# wszystkie atrybuty liczbowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>std/mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dissim</th>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.265102</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.015529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el0</th>\n",
       "      <td>0.618960</td>\n",
       "      <td>0.179363</td>\n",
       "      <td>0.289781</td>\n",
       "      <td>0.016103</td>\n",
       "      <td>0.963830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el1</th>\n",
       "      <td>0.231892</td>\n",
       "      <td>0.161531</td>\n",
       "      <td>0.696578</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.961220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el2</th>\n",
       "      <td>0.103617</td>\n",
       "      <td>0.135753</td>\n",
       "      <td>1.310146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.966240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el3</th>\n",
       "      <td>0.067084</td>\n",
       "      <td>0.086823</td>\n",
       "      <td>1.294241</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.920950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat72</th>\n",
       "      <td>16.759097</td>\n",
       "      <td>7.327707</td>\n",
       "      <td>0.437238</td>\n",
       "      <td>-1.619100</td>\n",
       "      <td>27.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat73</th>\n",
       "      <td>15.879577</td>\n",
       "      <td>7.959157</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>-1.499400</td>\n",
       "      <td>27.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat74</th>\n",
       "      <td>17.036289</td>\n",
       "      <td>7.197951</td>\n",
       "      <td>0.422507</td>\n",
       "      <td>-1.619100</td>\n",
       "      <td>27.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat75</th>\n",
       "      <td>29.675829</td>\n",
       "      <td>16.772171</td>\n",
       "      <td>0.565180</td>\n",
       "      <td>-1.000300</td>\n",
       "      <td>90.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat76</th>\n",
       "      <td>0.492640</td>\n",
       "      <td>0.344966</td>\n",
       "      <td>0.700240</td>\n",
       "      <td>0.057908</td>\n",
       "      <td>2.027700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean        std  std/mean       min        max\n",
       "dissim   0.004740   0.001257  0.265102  0.001272   0.015529\n",
       "el0      0.618960   0.179363  0.289781  0.016103   0.963830\n",
       "el1      0.231892   0.161531  0.696578  0.001310   0.961220\n",
       "el2      0.103617   0.135753  1.310146  0.000346   0.966240\n",
       "el3      0.067084   0.086823  1.294241  0.000185   0.920950\n",
       "...           ...        ...       ...       ...        ...\n",
       "stat72  16.759097   7.327707  0.437238 -1.619100  27.032000\n",
       "stat73  15.879577   7.959157  0.501220 -1.499400  27.032000\n",
       "stat74  17.036289   7.197951  0.422507 -1.619100  27.032000\n",
       "stat75  29.675829  16.772171  0.565180 -1.000300  90.528000\n",
       "stat76   0.492640   0.344966  0.700240  0.057908   2.027700\n",
       "\n",
       "[119 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df = pd.DataFrame(X.mean())\n",
    "std_df = pd.DataFrame(X.std())\n",
    "min_df = pd.DataFrame(X.min())\n",
    "max_df = pd.DataFrame(X.max())\n",
    "\n",
    "mean_std_df = mean_df.merge(std_df, left_index=True, right_index=True)\n",
    "mean_std_df[\"std/mean\"] = mean_std_df['0_y']/mean_std_df[\"0_x\"]\n",
    "mean_std_min_df = mean_std_df.merge(min_df, left_index=True, right_index=True)\n",
    "mean_std_min_max_df = mean_std_min_df.merge(max_df, left_index=True, right_index=True)\n",
    "\n",
    "mean_std_min_max_df.columns = ['mean', \"std\", \"std/mean\", 'min', 'max']\n",
    "pd.DataFrame.round(mean_std_min_max_df,decimals=4).to_csv(\"./data_desc.csv\")\n",
    "mean_std_min_max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca = StandardScaler()\n",
    "X_std = sca.fit_transform(X)\n",
    "X_std = pd.DataFrame(X_std, columns=X.columns)\n",
    "\n",
    "mean_df = pd.DataFrame(X_std.mean())\n",
    "std_df = pd.DataFrame(X_std.std())\n",
    "min_df = pd.DataFrame(X_std.min())\n",
    "max_df = pd.DataFrame(X_std.max())\n",
    "\n",
    "mean_std_df = mean_df.merge(std_df, left_index=True, right_index=True)\n",
    "mean_std_min_df = mean_std_df.merge(min_df, left_index=True, right_index=True)\n",
    "mean_std_min_max_df = mean_std_min_df.merge(max_df, left_index=True, right_index=True)\n",
    "\n",
    "mean_std_min_max_df.columns = ['mean', \"std\", 'min', 'max']\n",
    "mean_std_min_max_df\n",
    "pd.DataFrame.round(mean_std_min_max_df,decimals=4).to_csv(\"./data_std_desc.csv\")\n",
    "# mean_std_min_max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dissim</th>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.015529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el0</th>\n",
       "      <td>0.618960</td>\n",
       "      <td>0.179363</td>\n",
       "      <td>0.016103</td>\n",
       "      <td>0.963830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el1</th>\n",
       "      <td>0.231892</td>\n",
       "      <td>0.161531</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.961220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el2</th>\n",
       "      <td>0.103617</td>\n",
       "      <td>0.135753</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.966240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el3</th>\n",
       "      <td>0.067084</td>\n",
       "      <td>0.086823</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.920950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat72</th>\n",
       "      <td>16.759097</td>\n",
       "      <td>7.327707</td>\n",
       "      <td>-1.619100</td>\n",
       "      <td>27.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat73</th>\n",
       "      <td>15.879577</td>\n",
       "      <td>7.959157</td>\n",
       "      <td>-1.499400</td>\n",
       "      <td>27.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat74</th>\n",
       "      <td>17.036289</td>\n",
       "      <td>7.197951</td>\n",
       "      <td>-1.619100</td>\n",
       "      <td>27.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat75</th>\n",
       "      <td>29.675829</td>\n",
       "      <td>16.772171</td>\n",
       "      <td>-1.000300</td>\n",
       "      <td>90.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat76</th>\n",
       "      <td>0.492640</td>\n",
       "      <td>0.344966</td>\n",
       "      <td>0.057908</td>\n",
       "      <td>2.027700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean        std       min        max\n",
       "dissim   0.004740   0.001257  0.001272   0.015529\n",
       "el0      0.618960   0.179363  0.016103   0.963830\n",
       "el1      0.231892   0.161531  0.001310   0.961220\n",
       "el2      0.103617   0.135753  0.000346   0.966240\n",
       "el3      0.067084   0.086823  0.000185   0.920950\n",
       "...           ...        ...       ...        ...\n",
       "stat72  16.759097   7.327707 -1.619100  27.032000\n",
       "stat73  15.879577   7.959157 -1.499400  27.032000\n",
       "stat74  17.036289   7.197951 -1.619100  27.032000\n",
       "stat75  29.675829  16.772171 -1.000300  90.528000\n",
       "stat76   0.492640   0.344966  0.057908   2.027700\n",
       "\n",
       "[119 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 10, True: 109})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(mean_std_min_max_df['min']<0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 96, True: 23})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter((mean_std_min_max_df['max']>=0.9) & (mean_std_min_max_df['max']<=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11103     0]\n",
      " [ 3897     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85     11103\n",
      "           1       0.00      0.00      0.00      3897\n",
      "\n",
      "    accuracy                           0.74     15000\n",
      "   macro avg       0.37      0.50      0.43     15000\n",
      "weighted avg       0.55      0.74      0.63     15000\n",
      "\n",
      "balanced_accuracy_score:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Instalowane\\Programy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Klasa wiÄ™kszoÅ›ciowa to 0 ~74%. To byÅ‚aby trafnoÅ›Ä‡ klasyfikatora Zero Rule.\n",
    "y_pred = np.zeros(data.shape[0])\n",
    "print(confusion_matrix(y, y_pred))\n",
    "print(classification_report(y, y_pred))\n",
    "print(\"balanced_accuracy_score: \", balanced_accuracy_score(y, y_pred, adjusted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity = 0/(0+3897)\n",
    "specificity = 11103/(11103+0)\n",
    "G_mean = pow(sensitivity*specificity,0.5)\n",
    "G_mean # 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":  0.3499248874695394\n"
     ]
    }
   ],
   "source": [
    "sca = StandardScaler()\n",
    "X_std = sca.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.scatter(X_pca[y==0][:,0], X_pca[y==0][:,1], color='red', edgecolor='black')\n",
    "plt.scatter(X_pca[y==1][:,0], X_pca[y==1][:,1], color='blue', edgecolor='yellow')\n",
    "\n",
    "plt.savefig(\"./rysunki/PCA_2D.svg\")\n",
    "print(\": \", sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import interactive\n",
    "%matplotlib qt  \n",
    "# wx, gtk, osx, tk, empty uses default\n",
    "\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "X_pca = pca.fit_transform(X_std)[:15000]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "ax = plt.axes(projection='3d')\n",
    "y_5k = y[:15000]\n",
    "ax.scatter3D(X_pca[y_5k==0][:,0], X_pca[y_5k==0][:,1], X_pca[y_5k==0][:,2], color='red', edgecolor='black')\n",
    "ax.scatter3D(X_pca[y_5k==1][:,0], X_pca[y_5k==1][:,1], X_pca[y_5k==1][:,2], color='blue', edgecolor='yellow')\n",
    "# ax.view_init(10, 0)\n",
    "plt.savefig(\"./rysunki/PCA_3D.svg\")\n",
    "print(\": \", sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# skf  = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "# X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "# y = np.array([0, 0, 1, 1])\n",
    "\n",
    "# for train_index, test_index in skf.split(X, y):\n",
    "#     print(\"TEST:\", test_index , \"TRAIN:\", train_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "'''\n",
    "JeÅ›li dane sÄ… posortowane w jakiÅ› sposÃ³b to wÅ‚Ä…czenie/wyÅ‚Ä…czenie mieszania moÅ¼e mieÄ‡ duÅ¼y wpÅ‚yw na uzyskanÄ… trafnoÅ›Ä‡.\n",
    "ZaÅ‚Ã³Å¼my, iÅ¼ mamy 100 przypadkÃ³w uczÄ…cych i uÅ¼ywamy StratifiedFold z 5 foldami. KaÅ¼dy fold skÅ‚ada siÄ™ z 20 przypadkÃ³w.\n",
    "Powiedzmy, Å¼e posiadamy atrybut kolor oczu i pierwsze 20 przypadkÃ³w to jedyne przypadki z niebieskim kolorem oczu.\n",
    "W iteracji, w ktÃ³rej te 20 przypadkÃ³w bÄ™dzie w foldzie przypadajÄ…cym na zbiÃ³r testowy okaÅ¼e siÄ™,\n",
    "Å¼e w zbiorze treningowym nie bÄ™dzie Å¼adnego takiego przypadku i nasza trafnoÅ›Ä‡ bardzo spadnie.\n",
    "\n",
    "Z drugiej strony w innym przypadku moÅ¼e zdarzyÄ‡ siÄ™ odwrotna sytuacja, w ktÃ³rej akurat kolor oczu niebieski\n",
    "zawsze bÄ™dzie prawidÅ‚owo klasyfikowany, choÄ‡ prÃ³bki z innÄ… wartoÅ›ciÄ… cechy wcale dobrze klasyfikowane byÄ‡ nie muszÄ….\n",
    "Wtedy nasza trafnoÅ›Ä‡ bÄ™dzie zbytnio wysoka w tej iteracji.\n",
    "\n",
    "TakÅ¼e warto wÅ‚Ä…czaÄ‡ mieszanie, gdy dane sÄ… w jakiÅ› sposÃ³b posortowane.\n",
    "Jednak jeÅ¼eli dane sÄ… zaleÅ¼ne czasowo, np. przez zmnieniajace siÄ™ trendy to nie powinniÅ›my ich mieszaÄ‡.\n",
    "Dane uczÄ…ce powinny byÄ‡ starsze w takim przypadku niÅ¼ dane testowe.\n",
    "\n",
    "''' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parametr C odpowiada za wielkoÅ›Ä‡ marginesu bÅ‚Ä™du. Nie wpÅ‚ywa na sam sposÃ³b liczenia trafnoÅ›ci ????.\n",
    "Im wiÄ™ksza wartoÅ›Ä‡ tym mniejszy margines i jest bardziej douczony do danych uczÄ…cych. \n",
    "Parametr class_weight wpÅ‚ywa na wartoÅ›Ä‡ parametru C dla konkretnej klasy decyzyjnej. \n",
    "Czyli Å›rodek marginesu bÄ™dzie bardziej lub mniej przesuniÄ™ty w stronÄ™ ktÃ³rejÅ› z klas decyzyjnych.\n",
    "WartoÅ›Ä‡ 'balanced' ustala wartoÅ›Ä‡ parametru class_weight odwrotnie proporcjonalnie do licznoÅ›ci klas.\n",
    "\n",
    "balanced_accuracy nie jest przeskalowanym accuracy.\n",
    "Jest to Å›rednia z wartoÅ›ci sensitivity (recall) dla kaÅ¼dej klasy decyzyjnej ??? SPRAWDZIÄ† DALEJ.\n",
    "\n",
    "Czy majÄ…c zbiÃ³r 15k przypadkÃ³w i 2 zrÃ³wnowaÅ¼one klasy, klasyfikator moÅ¼e z 10-krotnej CV \n",
    "uzyskiwaÄ‡ Å›rednie balanced_accuracy<0.5? JeÅ›li tak, to w jakiej sytuacji?\n",
    "Tak, moÅ¼e. JeÅ¼eli mamy idealny klasyfikator, to recall dla kaÅ¼dej klasy wynosi 1.\n",
    "JeÅ¼eli mamy najgorszy klasyfikator, np. poprzez zamianÄ™ klas decyzyjnych perfekcyjengo klasyfikatora, to recall wynosi 0.\n",
    "Z definicji balanced_accuracy to Å›rednia wartoÅ›ci recall dla kaÅ¼dej klasy. TakÅ¼e w tym wypadku wyjdzie 0.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.788 (+/-0.011) for {'C': 1, 'kernel': 'rbf'}\n",
      "0.610 (+/-0.045) for {'C': 1, 'kernel': 'sigmoid'}\n",
      "0.814 (+/-0.015) for {'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      2248\n",
      "           1       0.85      0.31      0.46       752\n",
      "\n",
      "    accuracy                           0.81      3000\n",
      "   macro avg       0.83      0.65      0.67      3000\n",
      "weighted avg       0.82      0.81      0.78      3000\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for balanced_accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.614 (+/-0.018) for {'C': 1, 'kernel': 'rbf'}\n",
      "0.494 (+/-0.064) for {'C': 1, 'kernel': 'sigmoid'}\n",
      "0.666 (+/-0.027) for {'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      2248\n",
      "           1       0.85      0.31      0.46       752\n",
      "\n",
      "    accuracy                           0.81      3000\n",
      "   macro avg       0.83      0.65      0.67      3000\n",
      "weighted avg       0.82      0.81      0.78      3000\n",
      "\n",
      "\n",
      "1339.5985343456268\n"
     ]
    }
   ],
   "source": [
    "# zero rule classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, balanced_accuracy_score\n",
    "import time\n",
    "data = pd.read_csv(\"./131767-svm.txt\", sep='\\t')\n",
    "data[:3]\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], \n",
    "                     'gamma': ['auto'],\n",
    "                     'C': [1],\n",
    "                     'class_weight': [None]}]\n",
    "#                     {'kernel': ['linear'], \n",
    "#                      'C': [1, 1000],\n",
    "#                     'class_weight': ['balanced', None]}]\n",
    "\n",
    "# tuned_parameters = [{'kernel': ['rbf'], \n",
    "#                      'C': [1, 1000]}]\n",
    "\n",
    "\n",
    "tuned_parameters = {'kernel':('linear', 'rbf', 'sigmoid'),\n",
    "              'C':[1, 10, 100]}\n",
    "\n",
    "tuned_parameters = {'kernel':['rbf', 'sigmoid', 'linear'],\n",
    "              'C':[1, ]}\n",
    "\n",
    "scores_list = ['accuracy', 'balanced_accuracy']\n",
    "start = time.time()\n",
    "for score in scores_list:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(random_state=42), \n",
    "                       tuned_parameters, \n",
    "                       scoring=score,\n",
    "                       cv=10,\n",
    "                      n_jobs=7)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# zero rule classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, balanced_accuracy_score\n",
    "import time\n",
    "data = pd.read_csv(\"./131767-svm.txt\", sep='\\t')\n",
    "data[:3]\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], \n",
    "                     'gamma': ['auto'],\n",
    "                     'C': [1],\n",
    "                     'class_weight': [None]}]\n",
    "\n",
    "scores = {'accuracy': make_scorer(accuracy_score),\n",
    "          'balanced_accuracy': make_scorer(balanced_accuracy_score)}\n",
    "parameters = {'kernel':('linear', 'rbf', 'sigmoid'),\n",
    "              'C':[1, 10, 100]}\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    clf = GridSearchCV(SVC(),\n",
    "                       param_grid=parameters,\n",
    "                       scoring=score,\n",
    "                       cv=StratifiedKFold(n_splits=10),\n",
    "                       n_jobs=7)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    " \n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    dump(clf, \"gscv_{}.joblib\".format(int(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "from skleanr.model_selection import KFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "clf = SVC(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"balanced_accuracy_score: \", balanced_accuracy_score(y_test, y_pred, adjusted=False))\n",
    "print(gmean(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarycja, bez uÅ¼ycia PCA\n",
    "sca = StandardScaler()\n",
    "X_train_std = sca.fit_transform(X_train)\n",
    "X_test_std = sca.transform(X_test)\n",
    "\n",
    "clf = LinearSVC(random_state=42)\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test_std)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"balanced_accuracy_score: \", balanced_accuracy_score(y_test, y_pred, adjusted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standaryzacja, PCA 3 wymiary\n",
    "sca = StandardScaler()\n",
    "X_train_std = sca.fit_transform(X_train)\n",
    "X_test_std = sca.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=119, random_state=42)\n",
    "X_train_std_pca = pca.fit_transform(X_train_std)\n",
    "X_test_std_pca = pca.transform(X_test_std)\n",
    "print(\"explained_variance_ratio_: \", sum(pca.explained_variance_ratio_))\n",
    "\n",
    "clf = SVC(random_state=42)\n",
    "clf.fit(X_train_std_pca, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test_std_pca)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"balanced_accuracy_score: \", balanced_accuracy_score(y_test, y_pred, adjusted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
    "# output model is the same for precision and recall with ties in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
