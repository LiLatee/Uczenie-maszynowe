{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as plt3d\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4880623 , 0.85270907, 0.1862322 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize([[115.9967,202.6615,44.2614]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./131767-svm.txt\", sep='\\t')\n",
    "data[:3]\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_count = collections.Counter(y)\n",
    "class_0_prc = classes_count[0]/(classes_count[1]+classes_count[0])\n",
    "class_1_prc = 1 - class_0_prc\n",
    "print(\"0: \", class_0_prc)\n",
    "print(\"1: \", class_1_prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections.Counter(X.dtypes)\n",
    "# wszystkie atrybuty liczbowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame(X.mean())\n",
    "std_df = pd.DataFrame(X.std())\n",
    "min_df = pd.DataFrame(X.min())\n",
    "max_df = pd.DataFrame(X.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_df = mean_df.merge(std_df, left_index=True, right_index=True)\n",
    "mean_std_min_df = mean_std_df.merge(min_df, left_index=True, right_index=True)\n",
    "mean_std_min_max_df = mean_std_min_df.merge(max_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_min_max_df.columns = ['mean', \"std\", 'min', 'max']\n",
    "mean_std_min_max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasa większościowa to 0 ~74%. To byłaby trafność klasyfikatora Zero Rule.\n",
    "y_pred = np.zeros(data.shape[0])\n",
    "print(confusion_matrix(y, y_pred))\n",
    "print(classification_report(y, y_pred))\n",
    "print(\"balanced_accuracy_score: \", balanced_accuracy_score(y, y_pred, adjusted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = 0/(0+3897)\n",
    "specificity = 11103/(11103+0)\n",
    "G_mean = pow(sensitivity*specificity,0.5)\n",
    "G_mean # 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca = StandardScaler()\n",
    "X_std = sca.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.scatter(X_pca[y==0][:,0], X_pca[y==0][:,1], color='red', edgecolor='black')\n",
    "plt.scatter(X_pca[y==1][:,0], X_pca[y==1][:,1], color='blue', edgecolor='yellow')\n",
    "\n",
    "plt.savefig(\"./rysunki/PCA_2D.svg\")\n",
    "print(\": \", sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import interactive\n",
    "%matplotlib qt  \n",
    "# wx, gtk, osx, tk, empty uses default\n",
    "\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "X_pca = pca.fit_transform(X_std)[:15000]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "ax = plt.axes(projection='3d')\n",
    "y_5k = y[:15000]\n",
    "ax.scatter3D(X_pca[y_5k==0][:,0], X_pca[y_5k==0][:,1], X_pca[y_5k==0][:,2], color='red', edgecolor='black')\n",
    "ax.scatter3D(X_pca[y_5k==1][:,0], X_pca[y_5k==1][:,1], X_pca[y_5k==1][:,2], color='blue', edgecolor='yellow')\n",
    "# ax.view_init(10, 0)\n",
    "# plt.savefig(\"./rysunki/t.svg\")\n",
    "print(\": \", sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# skf  = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "# X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "# y = np.array([0, 0, 1, 1])\n",
    "\n",
    "# for train_index, test_index in skf.split(X, y):\n",
    "#     print(\"TEST:\", test_index , \"TRAIN:\", train_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "'''\n",
    "Jeśli dane są posortowane w jakiś sposób to włączenie/wyłączenie mieszania może mieć duży wpływ na uzyskaną trafność.\n",
    "Załóżmy, iż mamy 100 przypadków uczących i używamy StratifiedFold z 5 foldami. Każdy fold składa się z 20 przypadków.\n",
    "Powiedzmy, że posiadamy atrybut kolor oczu i pierwsze 20 przypadków to jedyne przypadki z niebieskim kolorem oczu.\n",
    "W iteracji, w której te 20 przypadków będzie w foldzie przypadającym na zbiór testowy okaże się,\n",
    "że w zbiorze treningowym nie będzie żadnego takiego przypadku i nasza trafność bardzo spadnie.\n",
    "\n",
    "Z drugiej strony w innym przypadku może zdarzyć się odwrotna sytuacja, w której akurat kolor oczu niebieski\n",
    "zawsze będzie prawidłowo klasyfikowany, choć próbki z inną wartością cechy wcale dobrze klasyfikowane być nie muszą.\n",
    "Wtedy nasza trafność będzie zbytnio wysoka w tej iteracji.\n",
    "\n",
    "Także warto włączać mieszanie, gdy dane są w jakiś sposób posortowane.\n",
    "Jednak jeżeli dane są zależne czasowo, np. przez zmnieniajace się trendy to nie powinniśmy ich mieszać.\n",
    "Dane uczące powinny być starsze w takim przypadku niż dane testowe.\n",
    "\n",
    "''' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parametr C odpowiada za wielkość marginesu błędu. Nie wpływa na sam sposób liczenia trafności ????.\n",
    "Im większa wartość tym mniejszy margines i jest bardziej douczony do danych uczących. \n",
    "Parametr class_weight wpływa na wartość parametru C dla konkretnej klasy decyzyjnej. \n",
    "Czyli środek marginesu będzie bardziej lub mniej przesunięty w stronę którejś z klas decyzyjnych.\n",
    "Wartość 'balanced' ustala wartość parametru class_weight odwrotnie proporcjonalnie do liczności klas.\n",
    "\n",
    "balanced_accuracy nie jest przeskalowanym accuracy.\n",
    "Jest to średnia z wartości sensitivity (recall) dla każdej klasy decyzyjnej ??? SPRAWDZIĆ DALEJ.\n",
    "\n",
    "Czy mając zbiór 15k przypadków i 2 zrównoważone klasy, klasyfikator może z 10-krotnej CV \n",
    "uzyskiwać średnie balanced_accuracy<0.5? Jeśli tak, to w jakiej sytuacji?\n",
    "Tak, może. Jeżeli mamy idealny klasyfikator, to recall dla każdej klasy wynosi 1.\n",
    "Jeżeli mamy najgorszy klasyfikator, np. poprzez zamianę klas decyzyjnych perfekcyjengo klasyfikatora, to recall wynosi 0.\n",
    "Z definicji balanced_accuracy to średnia wartości recall dla każdej klasy. Także w tym wypadku wyjdzie 0.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.816 (+/-0.023) for {'C': 1, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.766 (+/-0.030) for {'C': 1, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.841 (+/-0.025) for {'C': 1, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.788 (+/-0.011) for {'C': 1, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.843 (+/-0.024) for {'C': 1000, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.835 (+/-0.016) for {'C': 1000, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.843 (+/-0.024) for {'C': 1000, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.858 (+/-0.021) for {'C': 1000, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.794 (+/-0.035) for {'C': 1, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "0.814 (+/-0.015) for {'C': 1, 'class_weight': None, 'kernel': 'linear'}\n",
      "0.785 (+/-0.025) for {'C': 1000, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "0.832 (+/-0.025) for {'C': 1000, 'class_weight': None, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      2248\n",
      "           1       0.81      0.59      0.68       752\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.84      0.77      0.80      3000\n",
      "weighted avg       0.86      0.86      0.85      3000\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for balanced_accuracy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# zero rule classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, balanced_accuracy_score\n",
    "import time\n",
    "data = pd.read_csv(\"./131767-svm.txt\", sep='\\t')\n",
    "data[:3]\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], \n",
    "                     'gamma': ['auto', 'scale'],\n",
    "                     'C': [1, 1000],\n",
    "                     'class_weight': ['balanced', None]},\n",
    "                    {'kernel': ['linear'], \n",
    "                     'C': [1, 1000],\n",
    "                    'class_weight': ['balanced', None]}]\n",
    "\n",
    "# tuned_parameters = [{'kernel': ['rbf'], \n",
    "#                      'C': [1, 1000]}]\n",
    "\n",
    "\n",
    "scores_list = ['accuracy', 'balanced_accuracy']\n",
    "start = time.time()\n",
    "for score in scores_list:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(random_state=42), \n",
    "                       tuned_parameters, \n",
    "                       scoring=score,\n",
    "                       cv=10,\n",
    "                      n_jobs=-1)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.metrics import geometric_mean_score as gmean\n",
    "from skleanr.model_selection import KFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "clf = SVC(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"balanced_accuracy_score: \", balanced_accuracy_score(y_test, y_pred, adjusted=False))\n",
    "print(gmean(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarycja, bez użycia PCA\n",
    "sca = StandardScaler()\n",
    "X_train_std = sca.fit_transform(X_train)\n",
    "X_test_std = sca.transform(X_test)\n",
    "\n",
    "clf = LinearSVC(random_state=42)\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test_std)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"balanced_accuracy_score: \", balanced_accuracy_score(y_test, y_pred, adjusted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standaryzacja, PCA 3 wymiary\n",
    "sca = StandardScaler()\n",
    "X_train_std = sca.fit_transform(X_train)\n",
    "X_test_std = sca.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=119, random_state=42)\n",
    "X_train_std_pca = pca.fit_transform(X_train_std)\n",
    "X_test_std_pca = pca.transform(X_test_std)\n",
    "print(\"explained_variance_ratio_: \", sum(pca.explained_variance_ratio_))\n",
    "\n",
    "clf = SVC(random_state=42)\n",
    "clf.fit(X_train_std_pca, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test_std_pca)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"balanced_accuracy_score: \", balanced_accuracy_score(y_test, y_pred, adjusted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
    "# output model is the same for precision and recall with ties in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
